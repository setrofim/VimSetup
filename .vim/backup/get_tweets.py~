#!/usr/bin/python
import os
import sys
import time
import logging
import cPickle as pickle
import python_twitter

DELAY = 60 * 60 # 1 hour
RATE_LIMIT = 130 # hourly wait limmit
MAX_ERRORS = 3 # maximum number of consequtive errors before giving up

logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')


def update_tweets_file(tweets, filename):
    if os.path.isfile(outfile):
        with open(outfile, 'rb') as fh:
            alltweets = pickle.load(fh)
    else:
        alltweets = []
    alltweets.extend(tweets)
    with open(outfile, 'wb') as wfh:
        pickle.dump(alltweets, wfh)

outfile = sys.argv[1]
if len(sys.argv) > 2:
    startpage = int(sys.argv[2])
else:
    startpage = 1

endpage = None

frystatuses = []
pageno = startpage
request_count = 0
twapi = python_twitter.Api()
total_tweet_count = 0
error_count = 0
try:
    while True:
        request_count  += 1
        if request_count >= RATE_LIMIT:
            logging.info('exceeded %d requests' % RATE_LIMIT)
            logging.info('updating %s' % outfile)
            update_tweets_file(frystatuses, outfile)
            total_tweet_count += len(frystatuses)
            frystatuses = []
            logging.info('waiting %d seconds' % DELAY)
            time.sleep(DELAY)
            request_count = 0
        else:
            logging.info('getting page %d' % pageno)
            try:
                stats = twapi.GetUserTimeline('stephenfry', count=200, page=pageno)
                error_count = 0
                frystatuses.extend(stats)
                logging.info('got %d tweets' % len(stats))
                if not len(stats): 
                    # we've reached the end of available tweets; no point in looking
                    # in other pages.
                    update_tweets_file(frystatuses, outfile)
                    total_tweet_count += len(frystatuses)
                    frystatuses = []
                    break
            except python_twitter.TwitterError, te:
                logging.warning('WARNING: %s' % str(te))
                error_count += 1
                if error_count >= MAX_ERRORS:
                    loggin.error('ERROR: %d errors in a row; giving up...' % MAX_ERRORS)
                    raise Exception('Maximum error count exceeded.')
                logging.info('waiting %d seconds' % DELAY)
                time.sleep(DELAY)
        pageno += 1
        if endpage and pageno >= endpage:
            update_tweets_file(frystatuses, outfile)
            total_tweet_count += len(frystatuses)
            frystatuses = []
            break
except Exception, e:
    logging.error('ERROR: %s' % str(e))

print 'Got a total of %d tweets.' % total_tweet_count

print 'Done.'

